{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10117a72-feda-4b3c-a05f-b8fb65ddf72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /home/ec2-user/SageMaker/.Trash-1000/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46c139ea-de23-4863-a28d-82f04dc9bf0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/train_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 191 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "import json\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "import os, torch, random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "MAX_CPUs = max(1, multiprocessing.cpu_count()-1)\n",
    "\n",
    "pandarallel.initialize(nb_workers = MAX_CPUs , progress_bar=False)\n",
    "    \n",
    "\n",
    "config = {\"max_length\": 1488} # 99 Percentile with Prompt. 1656 for CAUSAL\n",
    "\n",
    "id2label = {0:1, 1:2, 2:3, 3:4, 4:5}\n",
    "label2id = {5:4, 4:3, 3:2, 2:1, 1:0}\n",
    "\n",
    "SEED = 13\n",
    "\n",
    "def seed_everything(seed=13):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ed8ba15-ccf2-4f54-b3d7-ba585bf80df7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_fast = False)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f19de20-b5ae-4bfc-969b-a81a9213f69a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>output</th>\n",
       "      <th>orig_instruction</th>\n",
       "      <th>orig_criteria</th>\n",
       "      <th>orig_score1_description</th>\n",
       "      <th>orig_score2_description</th>\n",
       "      <th>orig_score3_description</th>\n",
       "      <th>orig_score4_description</th>\n",
       "      <th>orig_score5_description</th>\n",
       "      <th>orig_response</th>\n",
       "      <th>orig_reference_answer</th>\n",
       "      <th>orig_feedback</th>\n",
       "      <th>orig_score</th>\n",
       "      <th>input</th>\n",
       "      <th>context_inst</th>\n",
       "      <th>context_resp</th>\n",
       "      <th>context_inst_resp</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30609</th>\n",
       "      <td>###Task Description:\\nAn instruction (might in...</td>\n",
       "      <td>The response demonstrates a general understand...</td>\n",
       "      <td>I'm working on a project that involves creatin...</td>\n",
       "      <td>How well does the model handle ambiguity and v...</td>\n",
       "      <td>The model cannot handle ambiguous or vague inp...</td>\n",
       "      <td>The model struggles with ambiguous or vague in...</td>\n",
       "      <td>The model generally handles ambiguous or vague...</td>\n",
       "      <td>The model handles ambiguous or vague inputs we...</td>\n",
       "      <td>The model expertly handles ambiguous or vague ...</td>\n",
       "      <td>To handle ambiguous or vague inputs, the chatb...</td>\n",
       "      <td>To handle ambiguous or vague inputs, the chatb...</td>\n",
       "      <td>The response demonstrates a general understand...</td>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>[Chatbots can be used to provide users with a ...</td>\n",
       "      <td>[To minimize the need for human feedback, a he...</td>\n",
       "      <td>[Unlike word processors, NLP considers the str...</td>\n",
       "      <td>Test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             instruction  \\\n",
       "30609  ###Task Description:\\nAn instruction (might in...   \n",
       "\n",
       "                                                  output  \\\n",
       "30609  The response demonstrates a general understand...   \n",
       "\n",
       "                                        orig_instruction  \\\n",
       "30609  I'm working on a project that involves creatin...   \n",
       "\n",
       "                                           orig_criteria  \\\n",
       "30609  How well does the model handle ambiguity and v...   \n",
       "\n",
       "                                 orig_score1_description  \\\n",
       "30609  The model cannot handle ambiguous or vague inp...   \n",
       "\n",
       "                                 orig_score2_description  \\\n",
       "30609  The model struggles with ambiguous or vague in...   \n",
       "\n",
       "                                 orig_score3_description  \\\n",
       "30609  The model generally handles ambiguous or vague...   \n",
       "\n",
       "                                 orig_score4_description  \\\n",
       "30609  The model handles ambiguous or vague inputs we...   \n",
       "\n",
       "                                 orig_score5_description  \\\n",
       "30609  The model expertly handles ambiguous or vague ...   \n",
       "\n",
       "                                           orig_response  \\\n",
       "30609  To handle ambiguous or vague inputs, the chatb...   \n",
       "\n",
       "                                   orig_reference_answer  \\\n",
       "30609  To handle ambiguous or vague inputs, the chatb...   \n",
       "\n",
       "                                           orig_feedback orig_score input  \\\n",
       "30609  The response demonstrates a general understand...          3         \n",
       "\n",
       "                                            context_inst  \\\n",
       "30609  [Chatbots can be used to provide users with a ...   \n",
       "\n",
       "                                            context_resp  \\\n",
       "30609  [To minimize the need for human feedback, a he...   \n",
       "\n",
       "                                       context_inst_resp split  \n",
       "30609  [Unlike word processors, NLP considers the str...  Test  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet(\"../prometheus_with_contexts.parquet\")\n",
    "data.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ad126a-fb57-4508-a600-f1dc89eae716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_text(row, is_test = False):\n",
    "    inst = row[\"instruction\"].replace(\"###Task Description:\\n\",\"<|system|>\\n\")\n",
    "    inst = inst.replace(\"\\n\\n###The\", \"<|end|>\\n\\n<|user|>\\n###The\")\n",
    "    inst = inst.replace(\"\\n\\n###Feedback: \", \"<|end|>\\n\\n<|assistant|>\")\n",
    "    \n",
    "    return inst\n",
    " \n",
    "    \n",
    "def generate_and_tokenize_prompt(prompt):                                                           \n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length= config[\"max_length\"],\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    return result                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d52ebb8-7834-48bd-bab7-4a00e5a9202f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
      "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
      "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
      "3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\"\n",
      "4. Please do not generate any other opening, closing, and explanations.<|end|>\n",
      "\n",
      "<|user|>\n",
      "###The instruction to evaluate:\n",
      "I am working on a research project that involves predicting the impacts of climate change on the agricultural sector. I have data from various sources including meteorological observations, historical crop yields, farmer interviews, and satellite imagery. I am struggling to integrate this diverse data into a cohesive analysis that could provide comprehensive insights. How can I effectively merge these diverse sources of data to create a holistic model that can predict the impacts of climate change on agriculture?\n",
      "\n",
      "###Response to evaluate:\n",
      "To merge your diverse sources of data and predict the impacts of climate change on agriculture, you need to follow a systematic approach. Begin with data preprocessing where all your data is cleaned and ready for analysis. Then, collaborate with experts from different fields for a better understanding of the data. Meteorologists can offer insights into the weather data, while agronomists can help with crop yields data. To merge these datasets, you should employ data integration techniques. Machine learning algorithms can handle diverse data types and find patterns within them. Develop your predictive model using suitable algorithms. Once you've trained your model, validate it with a subset of your data not used in training. Interpret the results in the context of your problem. Finally, refine your model based on the insights gained from the validation and interpretation stage. This approach should help you to integrate the diverse data sources effectively.\n",
      "\n",
      "###Reference Answer (Score 5):\n",
      "To create a holistic model that predicts the impacts of climate change on the agriculture sector, you'll need to carefully integrate your diverse datasets. Here's a step-by-step process:\n",
      "\n",
      "1. Data Preprocessing: Ensure all data is cleaned and preprocessed. For meteorological data and historical crop yields, time-series analysis will be crucial. Farmer interviews should be transcribed and coded for qualitative analysis, and satellite imagery analyzed using image processing techniques.\n",
      "\n",
      "2. Interdisciplinary Collaboration: Given the diverse nature of your data, it may be beneficial to collaborate with experts in different fields. Meteorologists can help interpret weather data, while agronomists can provide insights on crop yields. Sociologists or anthropologists could assist in interpreting qualitative data from farmer interviews.\n",
      "\n",
      "3. Data Integration: Use data integration techniques to merge these datasets. For example, machine learning algorithms can handle diverse data types and find complex patterns within them. A set of algorithms can be trained on your different datasets individually and their predictions can be combined (an ensemble) or they can feed into an overarching model.\n",
      "\n",
      "4. Model Development: Develop a predictive model using suitable algorithms. Given the complexity of your problem, advanced machine learning techniques, such as neural networks or random forest, may be appropriate.\n",
      "\n",
      "5. Validation and Interpretation: Validate your model using a subset of your data not used in training. It's important to interpret your results in the context of the problem. For instance, how do changes in weather patterns affect crop yields? What are the farmers' perceptions of these changes? \n",
      "\n",
      "6. Iterative Refinement: Predictive models are rarely perfect in their first iteration. Use the insights gained from the validation and interpretation stage to refine your model. This is an iterative process that improves the model over time.\n",
      "\n",
      "Following this approach should enable you to leverage the diverse data sources to provide comprehensive and discerning solutions to the impacts of climate change on agriculture.\n",
      "\n",
      "###Score Rubrics:\n",
      "[Is the model capable of combining data from multiple sources or scenarios to offer all-inclusive solutions?]\n",
      "Score 1: The model struggles to blend information from diverse sources, leading to solutions that are limited or biased.\n",
      "Score 2: The model sporadically amalgamates facts from a range of sources, yet the ensuing solutions lack profundity or lucidity.\n",
      "Score 3: The model frequently compiles information from varied contexts, yielding fairly holistic solutions, however it lacks regularity.\n",
      "Score 4: The model continually merges details from different sources, supplying complete and diverse solutions with minor deficiencies.\n",
      "Score 5: The model outshines in assimilating data from a wide array of sources or situations, persistently providing thorough and discerning solutions that tackle all facets of the problem.<|end|>\n",
      "\n",
      "<|assistant|>\n"
     ]
    }
   ],
   "source": [
    "data[\"text\"] = data.parallel_apply(create_text, axis = 1)\n",
    "data[\"label\"] = data[\"orig_score\"].parallel_apply(lambda x: int(x)-1)\n",
    "\n",
    "print(data[\"text\"].sample(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccad1a2f-1177-4c4e-ba99-2affa8c4abf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    1.000042\n",
      "1    0.998937\n",
      "2    1.003000\n",
      "3    1.001149\n",
      "4    0.996892\n",
      "Name: count, dtype: float64 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7940</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63636</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24096</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9014</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81223</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25796</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91060</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28140</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64938</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32704</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      orig_score  label\n",
       "7940           5      4\n",
       "63636          2      1\n",
       "24096          3      2\n",
       "9014           2      1\n",
       "81223          4      3\n",
       "25796          2      1\n",
       "91060          4      3\n",
       "28140          1      0\n",
       "64938          1      0\n",
       "32704          5      4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = data[data[\"split\"] == \"Train\"]\n",
    "\n",
    "val_df = data[data[\"split\"] == \"Test\"]\n",
    "\n",
    "\n",
    "print(train_df.shape[0]/(train_df[\"label\"].value_counts().sort_index()*train_df[\"label\"].nunique()), \"\\n\") # Weights for Loss balance\n",
    "\n",
    "train_df.loc[:,[\"orig_score\",\"label\"]].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22ffb683-687e-4aae-b17e-3fc8175973e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# leng = data[\"text\"].parallel_apply(lambda x : len(tokenizer(x).input_ids))\n",
    "# np.quantile(leng, 0.975), np.quantile(leng, 0.99), np.quantile(leng, 0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f72d2ddd-ad11-468e-abdc-350f22ee12e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=24): 100%|██████████| 94954/94954 [01:34<00:00, 1007.53 examples/s]\n",
      "Map (num_proc=24): 100%|██████████| 4998/4998 [00:07<00:00, 678.86 examples/s]\n",
      "Saving the dataset (3/3 shards): 100%|██████████| 94954/94954 [00:11<00:00, 8622.21 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4998/4998 [00:00<00:00, 20809.68 examples/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict({\"text\":train_df[\"text\"].values, \"label\":train_df[\"label\"].values})\n",
    "val_dataset = Dataset.from_dict({\"text\":val_df[\"text\"].values, \"label\":val_df[\"label\"].values})\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt, input_columns = \"text\", num_proc = 24)\n",
    "tokenized_val_dataset = val_dataset.map(generate_and_tokenize_prompt,input_columns = \"text\", num_proc = 24)\n",
    "\n",
    "tokenized_train_dataset.save_to_disk(\"./tokenized_train_dataset\")\n",
    "tokenized_val_dataset.save_to_disk(\"./tokenized_val_dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_env",
   "language": "python",
   "name": "train_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
