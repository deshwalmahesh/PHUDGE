{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24b7d86-a838-446f-a3d4-07a3f47d5b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf /home/ec2-user/SageMaker/.Trash-1000/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9195aa3b-728d-4b43-8550-ecb862b48c25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/train_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 191 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "import json\n",
    "import random\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "\n",
    "import os, torch, random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "MAX_CPUs = max(1, multiprocessing.cpu_count()-1)\n",
    "\n",
    "pandarallel.initialize(nb_workers = MAX_CPUs , progress_bar=False)\n",
    "    \n",
    "\n",
    "config = {\"max_length\": 1656}\n",
    "\n",
    "SEED = 13\n",
    "\n",
    "def seed_everything(seed=13):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75dd7014-dc16-48c0-935e-f7efde42d539",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\", use_fast = False)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ff79b2e-652d-484f-ba87-8fd3135665b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_text(row, is_test = False):\n",
    "    inst = row[\"instruction\"].replace(\"###Task Description:\\n\",\"<|system|>\\n\")\n",
    "    inst = inst.replace(\"\\n\\n###The\", \"<|end|>\\n\\n<|user|>\\n###The\")\n",
    "    inst = inst.replace(\"\\n\\n###Feedback: \", \"<|end|>\\n\\n<|assistant|>\\n\")\n",
    "    \n",
    "    if is_test: return inst\n",
    "    else: out = row[\"output\"].strip() + tokenizer.eos_token\n",
    "    \n",
    "    return inst + out\n",
    " \n",
    "    \n",
    "def generate_and_tokenize_prompt(prompt):                                                           \n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length= config[\"max_length\"],\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69e8c676-419b-48a4-8e6d-2e55b221309d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
      "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
      "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
      "3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\"\n",
      "4. Please do not generate any other opening, closing, and explanations.<|end|>\n",
      "\n",
      "<|user|>\n",
      "###The instruction to evaluate:\n",
      "I am working on a research project that involves predicting the impacts of climate change on the agricultural sector. I have data from various sources including meteorological observations, historical crop yields, farmer interviews, and satellite imagery. I am struggling to integrate this diverse data into a cohesive analysis that could provide comprehensive insights. How can I effectively merge these diverse sources of data to create a holistic model that can predict the impacts of climate change on agriculture?\n",
      "\n",
      "###Response to evaluate:\n",
      "To merge your diverse sources of data and predict the impacts of climate change on agriculture, you need to follow a systematic approach. Begin with data preprocessing where all your data is cleaned and ready for analysis. Then, collaborate with experts from different fields for a better understanding of the data. Meteorologists can offer insights into the weather data, while agronomists can help with crop yields data. To merge these datasets, you should employ data integration techniques. Machine learning algorithms can handle diverse data types and find patterns within them. Develop your predictive model using suitable algorithms. Once you've trained your model, validate it with a subset of your data not used in training. Interpret the results in the context of your problem. Finally, refine your model based on the insights gained from the validation and interpretation stage. This approach should help you to integrate the diverse data sources effectively.\n",
      "\n",
      "###Reference Answer (Score 5):\n",
      "To create a holistic model that predicts the impacts of climate change on the agriculture sector, you'll need to carefully integrate your diverse datasets. Here's a step-by-step process:\n",
      "\n",
      "1. Data Preprocessing: Ensure all data is cleaned and preprocessed. For meteorological data and historical crop yields, time-series analysis will be crucial. Farmer interviews should be transcribed and coded for qualitative analysis, and satellite imagery analyzed using image processing techniques.\n",
      "\n",
      "2. Interdisciplinary Collaboration: Given the diverse nature of your data, it may be beneficial to collaborate with experts in different fields. Meteorologists can help interpret weather data, while agronomists can provide insights on crop yields. Sociologists or anthropologists could assist in interpreting qualitative data from farmer interviews.\n",
      "\n",
      "3. Data Integration: Use data integration techniques to merge these datasets. For example, machine learning algorithms can handle diverse data types and find complex patterns within them. A set of algorithms can be trained on your different datasets individually and their predictions can be combined (an ensemble) or they can feed into an overarching model.\n",
      "\n",
      "4. Model Development: Develop a predictive model using suitable algorithms. Given the complexity of your problem, advanced machine learning techniques, such as neural networks or random forest, may be appropriate.\n",
      "\n",
      "5. Validation and Interpretation: Validate your model using a subset of your data not used in training. It's important to interpret your results in the context of the problem. For instance, how do changes in weather patterns affect crop yields? What are the farmers' perceptions of these changes? \n",
      "\n",
      "6. Iterative Refinement: Predictive models are rarely perfect in their first iteration. Use the insights gained from the validation and interpretation stage to refine your model. This is an iterative process that improves the model over time.\n",
      "\n",
      "Following this approach should enable you to leverage the diverse data sources to provide comprehensive and discerning solutions to the impacts of climate change on agriculture.\n",
      "\n",
      "###Score Rubrics:\n",
      "[Is the model capable of combining data from multiple sources or scenarios to offer all-inclusive solutions?]\n",
      "Score 1: The model struggles to blend information from diverse sources, leading to solutions that are limited or biased.\n",
      "Score 2: The model sporadically amalgamates facts from a range of sources, yet the ensuing solutions lack profundity or lucidity.\n",
      "Score 3: The model frequently compiles information from varied contexts, yielding fairly holistic solutions, however it lacks regularity.\n",
      "Score 4: The model continually merges details from different sources, supplying complete and diverse solutions with minor deficiencies.\n",
      "Score 5: The model outshines in assimilating data from a wide array of sources or situations, persistently providing thorough and discerning solutions that tackle all facets of the problem.<|end|>\n",
      "\n",
      "<|assistant|>\n",
      "The response provides a comprehensive solution by illustrating a structured approach to integrating diverse data sources to create a model for predicting the impacts of climate change on agriculture. It correctly identifies the need for data preprocessing, collaboration with experts, data integration, model development, validation and interpretation, and iterative refinement. However, the response could have elaborated more on the specific machine learning techniques and how the interpretation of results can drive model refinement, to give a more complete view of the model building process. Furthermore, the potential for different types of machine learning algorithms to handle the diverse data types, and how they can be used in combination for a more robust model, was only briefly touched upon. So the overall score is 4. [RESULT] 4<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet(\"../prometheus_with_contexts.parquet\")\n",
    "\n",
    "data[\"text\"] = data.parallel_apply(create_text, axis = 1)\n",
    "\n",
    "print(data[\"text\"].sample(1).values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c834dad5-59bd-415b-8361-8b277c9879f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = data[data[\"split\"] == \"Train\"]\n",
    "val_df = data[data[\"split\"] == \"Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0801b05-6a4d-4690-88c9-4397f24aa3b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=8): 100%|██████████| 94954/94954 [02:02<00:00, 772.88 examples/s] \n",
      "Map (num_proc=8): 100%|██████████| 4998/4998 [00:07<00:00, 708.79 examples/s] \n",
      "Saving the dataset (6/6 shards): 100%|██████████| 94954/94954 [00:09<00:00, 10219.01 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4998/4998 [00:00<00:00, 9779.40 examples/s] \n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset.from_dict({\"text\": train_df[\"text\"].values})\n",
    "val_dataset = Dataset.from_dict({\"text\": val_df[\"text\"].values})\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt, input_columns = \"text\", num_proc = 8)\n",
    "tokenized_val_dataset = val_dataset.map(generate_and_tokenize_prompt,input_columns = \"text\", num_proc = 8)\n",
    "\n",
    "tokenized_train_dataset.save_to_disk(\"./tokenized_train_dataset\")\n",
    "tokenized_val_dataset.save_to_disk(\"./tokenized_val_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "119032c5-34bd-4813-a1b4-a5db3c40fcdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1656, 1656)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_train_dataset[0][\"input_ids\"]), config[\"max_length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dfd62c2-514f-4b57-a416-4d9851e44b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><s>  <|system|> An instruction (might include an Input inside it), a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing a evaluation criteria are given.\n",
      "1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
      "2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.\n",
      "3. The output format should look as follows: \"Feedback: (write a feedback for criteria) [RESULT] (an integer number between 1 and 5)\"\n",
      "4. Please do not generate any other opening, closing, and explanations. <|end|> <|user|> ###The instruction to evaluate:\n",
      "You are a well-known psychiatrist who has a reputation for being empathetic and understanding. A client comes to you saying they've had a really hard day at work. They describe their boss as being overly critical and not listening to their ideas, which has left them feeling frustrated and undervalued. They also mention feeling overwhelmed with the workload and a growing sense of loneliness as they are new to the city. How do you respond to them to make them feel heard and understood, as well as offering helpful advice?\n",
      "\n",
      "###Response to evaluate:\n",
      "It's indeed challenging to deal with a difficult boss and to carry a large workload, especially when you are new to a city and haven't established a supportive network. I would suggest taking a step back to think about your situation and perhaps speak to your boss regarding the issues you're facing. On the other hand, dealing with a large workload can be managed by prioritizing tasks, and maybe you can discuss it with your superiors too. \n",
      "\n",
      "In regards to feeling lonely, you might want to explore activities or groups that align with your interests to meet new people. And also, remember to take time for yourself to relax and destress. I'm here to assist you as we navigate through these issues.\n",
      "\n",
      "###Reference Answer (Score 5):\n",
      "I hear that you're dealing with quite a few challenging situations at once. It must be tough to have your ideas dismissed by your boss and to feel undervalued in your work environment. It's understandable that such experiences can lead to frustration and a feeling of being overwhelmed. \n",
      "\n",
      "It's important to acknowledge these feelings and not to dismiss them. Feeling heard and validated in our experiences can often be the first step towards resolving the challenges we face. So, I want you to know that your feelings are completely valid and it's okay to be frustrated and overwhelmed.\n",
      "\n",
      "In terms of dealing with your boss, have you considered seeking a private conversation with them to express your feelings? It's often beneficial to communicate what you're experiencing, using \"I\" statements to express how you feel when your ideas are not taken into consideration. This can lead to mutual understanding and possibly a change in behavior.\n",
      "\n",
      "About the workload, it might help to prioritize tasks and potentially delegate, if possible. Also, consider discussing your workload with your superiors. There might be a misunderstanding about what's manageable or they might have suggestions about how to handle the situation.\n",
      "\n",
      "On the personal front, feeling lonely, especially when you're new to a city, can be really hard. Seek out opportunities to meet new people, perhaps through hobbies, community activities, or online groups. It might take a bit of time, but gradually, you can build a network of friends and acquaintances.\n",
      "\n",
      "Remember, it's perfectly okay to have bad days and it's important to take care of your mental health. Consider incorporating activities into your daily routine that make you happy and help you unwind. This could be anything from reading, yoga, going for a walk, or even listening to your favorite music.\n",
      "\n",
      "Please know that you're not alone in this. I'm here to support you through this challenging time and together, we can work towards resolving these issues.\n",
      "\n",
      "###Score Rubrics:\n",
      "[Is the model able to identify and react correctly to the emotional context of the user's input?]\n",
      "Score 1: The model utterly fails to grasp the user's emotional context and responds in an unfitting manner.\n",
      "Score 2: The model sporadically identifies the emotional context but frequently replies in a manner that doesn't match the user's emotional status.\n",
      "Score 3: The model typically identifies the emotional context and reacts suitably, but occasionally misreads or misjudges the user's feelings.\n",
      "Score 4: The model often identifies the emotional context and reacts suitably, with minor cases of misreading or misjudging.\n",
      "Score 5: The model flawlessly identifies the emotional context of the user's input and consistently responds in a considerate and empathetic manner. <|end|> <|assistant|> The response was generally on point with acknowledging the emotional context of the client's struggles. However, the therapist failed to express empathy towards the client's feelings of frustration and loneliness, which are central to the client's predicament. The response provided suitable advice on dealing with a critical boss and overwhelming workload, but there was a lack of a personal touch, which might have made the client feel more understood and less alone. \n",
      "\n",
      "There was a misstep in not validating the client's feelings, which is crucial in an empathetic response. The advice provided about managing workload and dealing with loneliness was quite generic and could have been more personalized to the client's situation. So the overall score is 3. [RESULT] 3<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized_train_dataset[0][\"input_ids\"], skip_special_tokens = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eeb1be-31d6-42c4-8e21-4b97eb7785e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train_env",
   "language": "python",
   "name": "train_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
